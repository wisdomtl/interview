网络分层的好处是下层的可重用性，tcp不需要知道它传输的是http还是ftp亦或是SSH，
## 1. 物理层
- 二进制在物理媒体上传输

## 2. 数据链路层

## 3. 网络层（ip）
- 为数据包路由

## 4. 传输层（tcp，udp）
- 提供端到端接口

### tcp
- TCP 头部：
	+ sequence number（32位） 用于标识报文中第一个字节在整个数据流中的序号，用于确保有序
	+ ack number（32位），表示对上一个接收到的sequence number的确认，解决丢包。只有当ack位为1时才有效
	+ 滑动窗口大小
	+ tcp flag，有6个标志位 URG，ACK，PSH，RST，SYN，FIN
	+ 两个16位的端口号（源+目的）
- 基于字节流的，是面向连接的，可靠的点到点传输协议
- 采用确认和超时重传策略保证可靠传输
	- 确认：接收方检测出帧出错是不会返回确认帧并直接丢弃该帧
	- 超时重传：发送方发送数据报后启动倒计时，若规定时间内未收到确认才重传数据报
- 提供拥塞控制和流量控制
	- 采用大小可变的滑动窗口实现流量控制，窗口大小即是发送方发送但未收到确认的数据报数量
	- 慢启动：每个rtt（round trip time 往返时间）将滑动窗口翻倍。
	- 拥塞控制对链接是独立的
	- 但拥塞控制会导致tcp队头阻塞（tcp必须接收到完整正确顺序的数据包后才能提交给上层），使得单路 http/2 的速度没有多路 http/1 的快
- TCP通信过程太复杂并且开销大，一次TCP交换需要9个包： 三个连接包，四个断开包，一个request包，一个响应包。
- UDP通信过程简单，只需要一个查询包和一个响应包。

#### tcp三次握手建立连接
1. 发送方请求建立连接Syn报文 syn位置1(表示链接建立请求) ack位置0，seq number =x
2. 接收方确认请求 syn位置1，ack位置1，seq number = y  ack number = x+1
3. 发送方确认的确认 ack number = y+1
为啥不能两次：防止超时的连接请求报文到达服务器再次建立连接。

#### tcp四次挥手释放连接
- 4次挥手：发送方请求释放连接（Fin报文）-接收方确认（ACK置1）-接收方请求释放连接（Fin报文）-发送方确认-客户端等待 2MSL（报文最大生存时间） 的时间后依然没有收到回复（服务端没收到ack，则服务端会重新发送fin），则证明服务端已正常关闭，那么客户端也可以关闭连接了
- 为啥挥手要四次，因为TCP全双工，客户端请求释放连接时，只表示客户端没东西发了，但服务器还有数据要返回。

#### socket
- 套接字 = {传输层协议,源地址,源端口,目标地址,目标端口}，其中协议可以是tcp或udp，是不同主机进程间通信的端点
- 发送数据是不定长的，大数据会分包发送，使用头部约定的数据包长度，以标识数据包的尾部

# udp
- 用户数据包协议
- UDP提供的是无连接 无确认 不可靠服务的点到多点传输协议
- udp是基于报文的
- 发送前无需握手，发送完无需释放连接，传输效率高
- 每个数据包独立发送，不同数据包可能传输路径可能不同
- 没有拥塞控制
- 有差错校验，对udp头部和数据段都进行校验，服务端通过校验和发现出错时直接丢弃
- udp 依赖网络层的ip，udp数据包被包在ip数据包外层

## 5. 应用层（http）
# https
- https 是安全的 http，它 = http + ssl（Secure Sockets Layer）
- 是应用层协议，解决如何封装数据
- 无状态协议，服务器对用户操作没有记忆
- http 1.1 开始有keep-alive，保持链接，客户端和服务器的连接不会断开而是保持一段时间，为了效率（Connection：keep-alive，请求头部的该字段决定了链接是否会复用），如果客户端对同一个地址并发地发起多个http请求，则依然会建立多个链接。依然还存在请求的队头阻塞。
- http1.1 新增了pipeline，多个http资源可以并发地在一条tcp链接上发送（发送方不需要等待第一个资源确认了才发送第二个资源）。但接收方只能串行的处理响应，一个慢响应会阻塞所有快请求向上层提交（管道解决了请求的队头阻塞）
- Content-Length 用于表明传输数据的长度，因为现在链接不会关闭，所以需要通过该字段告诉客户端数据的结尾 。
- 明文通信，可能被窃听；不验证身份，可能被劫持；无法验证报文完整性，可能被篡改。
- HTTP协议使用默认80端口，HTTPS协议使用443端口
- 证书: 是服务器下发给客户端的，客户端用证书验证服务端身份。证书需要购买
- 证书包含：认证机构(CA)信息,公钥,域名,有效期,指纹(对证书进行hash运算,即证书摘要),指纹算法,数字签名(CA私钥加密的指纹)等

### HTTP2.0
- 1.0 每个http请求都要重新建立一条tcp链接，结束时要关闭链接，临时链接。
- 1.0 不压缩header，且每次通信都要重复发送head
- 1.0 不支持请求优先级
- 1.0 必须串行的地完成地发送资源（造成队头阻塞）
- 1.1 允许持久链接，接收方只能串行地处理不同请求，两个请求生命周期不能重叠，因为接收方无法确认数据的开始和结束（有效负荷字段写在header中），这会造成队头阻塞，多个并行请求需建立多条 tcp链接，无法复用。关闭链接只要在头部带上Connection:Close
- 2.0 支持header压缩，通讯双方缓存一个 header field 表，避免重复 header 传输
- 2.0 多路复用，将数据流分解成更小的帧（通过在头部廷加stream id，和帧大小），不同数据流的帧可以交错在一条tcp连接上发送，再根据所属流重新组装，实现了多请求并行传输的效果（时间片），解决了http层的队头阻塞（减轻了服务端的压力，每个客户端只建立了一条链接，服务器可以给更多的客户端建立连接）
- 2.0 支持优先级

#### 数据流
- 一个连接可承载任意数量的字节流
- 每个数据流有优先级信息，即该流上的数据帧发送的优先级：
公平多路复用（例如两个渐进的 JPEGs）：12121212
加权多路复用（2是1的两倍）：22122122121
反向顺序调度（例如2是密钥服务器推送的资源）：22221111
部分调度（流1被中止且未完整发送）：112222

### 加密解密
加密算法分为两类：对称加密和非对称加密。
- 对称加密：加密和解密用的都是相同的秘钥，优点是速度快，缺点是安全性低。常见的对称加密算法有DES、AES等等。
- 非对称加密：非对称加密有一个秘钥对，分为公钥和私钥。一般来说，私钥自己持有，公钥可以公开给对方，优点是安全性比对称加密高，缺点是数据传输效率比对称加密低。采用公钥加密的信息只有对应的私钥可以解密。常见的非对称加密包括RSA等。

#### 数字摘要
- 是明文摘要成128位密文的过程，比如MD5，SHA1

#### 数字签名
- 是用于验证信息完整性的和身份验证。
- 发送方将内容摘要并用私钥加密并发送，接收方用公钥解密摘要，再对原文求摘要，比对两个摘要，若相同则未被篡改

#### 数字证书
-  是为了解决公钥置信的问题、

### TLS
- 是 ssl3.0 的后续版本
- 分为 tls记录和tls握手
- tls 实现了加密数据，验证数据完整性，认证身份

#### tls握手过程
是一个借助于数字证书协商出对称加密密钥的过程
1. 客户端发出请求，说明支持的协议，客户端生成的随机数，支持的加密方法
2. 服务端返回证书，服务端生成的随机数
3. 客户端验证证书
4. 客户端使用证书中的公钥加密另一个新得随机数。并发送给服务器
5. 生成会话密钥：客户端和服务器分别用三个随机数生成相同的对称密钥
6. 服务器通知握手结束，之后就通过对称密钥通信
- 验证过程:
	0. 客户端 TLS 解析证书
	1. 证书是否过期
	2. CA是否可靠(查询信任的本地根证书)
	3. 证书是否被篡改(用户使用CA根公钥解密签名得到原始指纹,再对证书使用指纹算法得到新指纹,两指纹若不一样,则被篡改)
	4. 服务器域名和证书上的域名是否匹配

### QUIC
- quic建立在UDP之上，但实现了可靠传输，它更应是TCP 2.0，它包含tcp的所有特性 ：可靠性，拥塞控制，流量控制。
- quic 将 http2的流和帧的概念下移到了传输层，给每个数据流一个stream id，以及跟踪该字节流的字节范围（比如包1是从0-200，包2是从201-300），这将不能保证数据包的有序性，单个资源流的有序，多个流的顺序无法保证（比如服务器发送资源1.1-1.2-2，接收方的顺序可能是2-1.1-1.2），

### quic协议在弱网环境下表现较好的原因有以下几个方面：
- 避免tcp连接建立的三次握手：tcp协议需要进行三次握手才能建立连接，而在弱网环境下，网络延迟可能很高，连接建立的时间会比较长，增加了传输的时延。quic协议使用了基于udp的连接方式，避免了tcp连接建立的过程，从而降低了连接建立的时延。
- 快速恢复数据传输：在弱网环境下，网络抖动、丢包等问题非常普遍，这些问题会导致tcp协议进行拥塞控制，将传输速度降低以避免网络拥塞。但是这也会影响用户体验，因为传输速度变慢。quic协议采用快速应答机制和流级别的拥塞控制，能够快速恢复数据传输，提高了传输效率。
- 报文头部压缩：在传输过程中，报文头部的大小占据了很大一部分带宽，特别是在传输小数据量的场景下，这种情况更加明显。quic协议使用hpack算法对报文头部进行压缩，从而减少了报文头部的大小，提高了传输效率。

## 队头阻塞
- 一个大的（慢的）响应会阻塞其后面的响应。
- http1.0 通过多个http链接缓解该问题
- http2.0回到单个 TCP 连接，解决队头阻塞问题。这在 HTTP/1.1 中是不可能的，因为没有办法分辨一个块属于哪个资源，或者它在哪里结束，另一个块从哪里开始。HTTP/2 非常优雅地解决了这一问题，它在资源块之前添加了帧（frames）
- http2.0解决了http层的队头阻塞。但还有tcp队头阻塞，当发生丢包，tcp会先将失序数据存在缓冲区，待重传数据到来时才按照正确的顺序提交给上层，此时丢失的包会阻塞后续包提交给上层。
- quic 将http2 流和帧的概念下移到了传输层，解决了 tcp队头阻塞
- tls队头阻塞：tls加解密是整块进行的，tls记录可能分散在多个tcp包上，若tcp丢包则tls队头阻塞，quic的解决方案是将加解密分散处理，这样会拖慢加解密速度。

# 一次网络请求
1. 请求dns服务器解析ip地址
2. 三次握手建立TCP链接
3. tls握手
3. 请求内容封装成http报文---tcp分包 在链路上发送出去
4. 服务器解析报文响应
5. 关闭链接，四次握手

## Retrofit
- Retrofit 是一个 RESTful 的 HTTP 网络请求框架的封装
- Retrofit将Http请求抽象成预定义请求接口，使用运行时注解配置请求参数，通过动态代理生成请求对象 （调用Call.Factory生成OkHttp.call），并将response转换成业务数据
- 使用建造者模式，构建retrofit实例
- 使用工厂模式
	1. Call.Factory 构建请求，描述了如何通过request构建call对象，可以通过装饰者模式在okhttpClient外层包一层实现测试/正式服的域名切换
	2. Convert.Factory构建序列化/反序列化工厂，将ResponseBody转换成业务层数据，将请求转换成一个requestBody
- 使用装饰者模式
	1. 通过装饰者模式将响应回调抛到主线程，真正发起请求的是OkhttpCall，他外面又套了一层 ExecutorCallbackCall 扩展了该功能
- retrofit使用了外观模式，create(),隐藏了动态代理生成接口实例，通过Call.Factory生成请求的细节
- Retrofit.crate()将接口请求动态代理给了ServiceMethod的invoke方法（查找接口对应的ServiceMethod对象（没找到就当场使用反射遍历接口中的注解，并生成ServiceMethod对象对应一个业务接口，接口中的参数都会成为它的成员变量，存在ConcurrentHashMap中，键是Method）），在该方法中生成retrofit的call对象（内部会生成Okhttp3的call对象并发起同步或异步请求），并调用CallAdapter将call适配成response（CallAdapter，它负责将retrofit.call 转换成业务层喜欢的消费方式（比如 observable，suspend方法））

## httpdns
http协议80端口请求dns服务器，使用ip直接访问httpdns服务器，绕过了运营商 localDns，防劫持，省去了解析
httpdns能获取用户ip，可以返回最优ip地址
local dns：没有域名解析决定权，代理了用户向权威dns获取域名的过程，它会缓存解析结果，用ttl时间表示缓存是否过期。存在解析转发，转发给别的运营商，用户变成跨网访问

## 网络优化
1. 请求预热：发送无body的head请求，提前建立好tcp，tls链接，省掉dns，tcp，tls时间
2. 统一域：不同的业务的域名在客户端发出请求之前进行合并（因为若域名不同，请求不同业务时都需要dns解析，且都需要建立不同的tcp链接），使用统一的域，将请求不同的部分往后挪到接口部分，请求到达后端SLB后进行域名还原。okhttp链接复用最多保持5个空闲链接（通过调整最大空闲请求数，一个connection在内存中5k）
3. 有了统一的域之后，可以进行网络嗅探，择优进行IP直连，app启动时，拉取域对应的ip列表，并对所有ip进行嗅探ping接口，选择其中最优的ip 最为后续请求的直连ip，不需要进行dns解析
4. 对于可靠性要求高的请求，先入库，失败后重试
5. 网络切换时，自动关闭缓存池中现有的链接（客户端网络地址发生变化，原先的链接失效）
6. 减少数据传输量，protocolBuffer，图片压缩，webp，请求合适大小的图片
7. 无网环境下， 添加强制缓存的拦截器，对请求添加cache-control:max-age:1年

# tcp粘包，tcp分包
1. 半包：如果数据包太大，导致服务器 没有接收完整的包
2. 粘包：tcp基于字节流，不关心上层传输的具体内容，在一个tcp报文中可能存在多个http包（发送端粘包：http包太小，tcp为了提高效率，所以粘包，接收端粘包：接收端没有及时处理接收缓冲区的数据，读取时出现粘包）
3. 分包：tcp基于字节流，tcp不关心上层传输的具体内容，一个大的http包可能被分在多个tcp报文上（发送http太大）
- 粘包分包解决方案：定长消息，用特殊字符标记消息边界，将消息长度写在消息头中

# tcp心跳包
- 通信双方处于idle状态时确保长链接的有效性，需要发送的特殊数据包给对方（ping），接收方给予回复（pong）
- tcp自带心态机制SO_KEEPALIVE，但不够灵活，所以在应用层上实现心跳
- Netty 使用  IdleStateHandler 根据超时时间监听读写事件，若发生超时则会触发回调，这个时候可以发送心跳包